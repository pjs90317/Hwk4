---
title: "Homework 4"
author: Patrick Sinclair
output: github_document
---
```{r setup, include=FALSE, echo = FALSE}
setwd("~/CCNY/Econometrics/Homework/Draft Hwk Files/Lab 2")
load("acs2017_ny_data.RData")
attach(acs2017_ny)
use_varb <- (AGE >= 25) & (AGE <= 70) & (LABFORCE == 2) & (WKSWORK2 > 4) & (UHRSWORK >= 35)
dat_use <- subset(acs2017_ny,use_varb)
detach()
attach(dat_use)
require(stargazer)
require(AER)
```
#### How important is a college degree in determining an individual's wages?  
A question that is even more relevant in the current economic climate than usual, it is one that seems particularly susceptible to the impact of external variables. Quality of tertiary institution, financial standing of family during one's upbringing, relevance to actual career path are potential confounding variables that immediately spring to mind.

To approach the problem, the subset has been expanded to include people in the workforce, between 25 and 70 (to account for the ever increasing retirement age), working full time hours at least 48 weeks of the year. I'll run several linear regressions on the subset to determine whether we can find a causal link between college degree and income, or whether we just observe some sort of correlation.

The first regression looks at the relationship between income and age and gender. I reduced the number of observations in the random uniform distribution to 0.05 as the length of the data set is 61,945 observations. To demonstrate the range of incomes at each age more clearly, the jitter of the plots has been reduced to 1 and the y-limit has been increased to 250,000 for the same reason. When I tested higher y-limits, the presentation lost clarity.
```{r, echo=FALSE}
setwd("~/CCNY/Econometrics/Homework/Draft Hwk Files/Homework-4")
age_gender <- lm(INCWAGE ~ AGE + female)
summary(age_gender)
plot(age_gender)
stargazer(age_gender, type = "text")
```

```{r echo=FALSE}
NNobs <- length(INCWAGE)
set.seed(12345)
graph_obs <- (runif(NNobs) < 0.05)
dat_graph <-subset(dat_use,graph_obs)  
```
```{r, echo=FALSE}
plot(INCWAGE ~ jitter(AGE, factor = 1), pch = 120, col = rgb(red = 0, green = 1, blue = 1, alpha = 0.3), ylim = c(0,250000), data = dat_graph)
predictedf <- data.frame(AGE = 25:70, female = 1)
predictedf$yhat <- predict(age_gender, newdata = predictedf)
lines(yhat ~ AGE, data = predictedf, col = rgb(1, 0, 0))
```
```{r, echo=FALSE}
plot(INCWAGE ~ jitter(female, factor = 2), pch = 120, col = rgb(red = 0, green = 1, blue = 1, alpha = 0.6), ylim = c(0,250000), data = dat_graph)
predicted <- data.frame(AGE = 25:70, female = 0:1)
predicted$yhat <- predict(age_gender, newdata = predicted)
lines(yhat ~ female, data = predicted, col = rgb(1, 0, 0, alpha = 0.3), lwd = 0.1)
```
From the summary, we see that the intercept of wages is 56373.20. The Ordinary Least Squares (OLS) coefficient for the age and gender variables is 584.31 and -19921.41 respectively. All three estimators are statistically significant to the 95% level. This is confirmed when we examine the t and p values for the estimators; the t-values for all three betas are well above the absolute critical value (critical t-value: 1.96) and the p-values are below 0.025; If we look at the confidence intervals:
```{r echo=FALSE} 
confint(age_gender, level=0.95)
```
We can be 95% confident that if there is in fact a relationship between income, age and gender, then we would observe values for the estimators within the boundaries above. All of the estimators we have observed sit within those intervals, so we have evidence to suggest that the correlations exist. Yet, when we take the R^2^ into consideration, it suggests that the model does not do very well at predicting income based on the variables of age and gender. I think this may be to do with the variables having opposite correlations with income. I included the plot of the gender variable to illustrate the conflicting regression lines between the two - I also adjusted the jitter and opaqueness of the colors on the second graph to highlight the higher density of large incomes received by men.

Now to compare levels of college education. I'm going to remove the gender variable, in an attempt to show the impact of earning a degree on income. Hopefully we see that degree holders earn a higher wage, regardless of gender.
```{r, echo=FALSE}
educ_indx <- factor((educ_nohs + 2*educ_hs + 3*educ_somecoll + 4*educ_college + 5*educ_advdeg), levels=c(1,2,3,4,5),labels = c("No HS","HS","SmColl","Bach","Adv"))
age_degree <- lm(INCWAGE ~ AGE + educ_nohs + educ_hs + educ_somecoll + educ_college + educ_advdeg)
summary(age_degree)
plot(age_degree)
stargazer(age_degree, type = "text")
```
```{r echo=FALSE}
NNobs <- length(INCWAGE)
set.seed(12345)
graph_obs <- (runif(NNobs) < 0.05)
dat_graph <-subset(dat_use,graph_obs)  
```
```{r, echo=FALSE}
plot(INCWAGE ~ jitter(AGE, factor = 1), pch = 120, col = rgb(red = 0, green = 1, blue = 1, alpha = 0.7), ylim = c(0,250000), data = dat_graph)
predicteddeg <- data.frame(AGE = 25:70, educ_nohs = 0, educ_hs = 0, educ_somecoll = 0, educ_college = 1, educ_advdeg = 1)
predicteddeg$yhat <- predict(age_degree, newdata = predicteddeg)
lines(yhat ~ AGE, data = predicteddeg, col = rgb(1, 0, 0))
```
In the above regression, education levels have been included as individual dummy variables - R did not include Advance Degree as a variable. All of the slope coefficient estimates for education levels are negative however, as educational attainment increases, the slope coefficients  become less negative. This suggests that as one's level of education increases, they potentially earn higher income.       

To double check this, I ran another regression, this time creating a factor to include the educational levels. On this occasion, R excluded No High School as a variable.
```{r, echo=FALSE}
educ_indx <- factor((educ_nohs + 2*educ_hs + 3*educ_somecoll + 4*educ_college + 5*educ_advdeg), levels=c(1,2,3,4,5),labels = c("NoHS","HS","SmColl","Bach","Adv"))
age_degreeb <- lm(INCWAGE ~ AGE + educ_indx)
summary(age_degreeb)
plot(age_degreeb)
stargazer(age_degreeb, type = "text")
```

```{r, echo=FALSE}
plot(INCWAGE ~ jitter(AGE, factor = 1), pch = 120, col = rgb(red = 0, green = 1, blue = 1, alpha = 0.7), ylim = c(0,250000), data = dat_graph)
predicteddegb <- data.frame(AGE, educ_nohs = 0, educ_hs = 0, educ_somecoll = 0, educ_college = 1, educ_advdeg = 1)
predicteddegb$yhat <- predict(age_degreeb, newdata = predicteddegb)
lines(yhat ~ AGE, data = predicteddegb, col = rgb(1, 0, 0))
```
All slope coefficients were estimated as positive, all with t-values and p-values that confirm statistical significance. Again referring to the confidence intervals:
```{r echo=FALSE} 
confint(age_degreeb, level=0.95)
```
None of the intervals contain 0 as a value, so we can be 95% confident that there is evidence to reject the H~0~ of no relationship. Again, all of the absolute t-values exceed the critical value of 1.96, the closest being the intercept, which at an absolute value of 2.249 still exceeds the required value to deem it statistically significant.

Up to this point, we have assumed that the variables are homoskedastic. That is, the variance in the errors in the observed values of the dependent variable remain constant. It is reasonable to assume that due to other influences such as career choices, location and other lifestyle factors, the variance of errors in income will not remain constant as our independent variables change. For instance, whether a young academic takes a role in a tertiary institution or trades the books for a corporate role, the difference in income may not be as drastic as a PhD holder who trades their academic position for a high end role in a banking or technology firm. In this case, the variables are heteroskedastic. If we adjust for heteroskedasticity, we observe the following:
```{r echo=FALSE}
coeftest(age_gender,vcovHC)
coeftest(age_degreeb,vcovHC)
```
Comparing these to our initial values, we notice that our coefficient estimates have remained the same. However, for the first regression run, the standard error (se) increased for the intercept and age coefficients, the t-values both increased and the p-values decreased. For the female (gender) coefficient, the se decreased, as did the t-value and p-value (this is due to the slope being negative, so the t and p-values were already situated in the left tail). The confidence interval would remain the same, as our estimator is consistent but the values have even less probability of falling within the 95% interval.

Up to now, we've looked at overall changes in the raw data. If we take a log of the y variable, we can look at percentage change of the dependent variable in response to changes in the independent variables.
```{r, echo=FALSE}
income <- (INCWAGE + 1)
age_genderlog <- lm(log(income) ~ AGE + female)
summary(age_genderlog)
plot(age_genderlog)
stargazer(age_genderlog, type = "text")
```
Now we are viewing a log-linear model. Comparing these coefficients to our original coefficients, we can see they are much smaller. Converting the Y into logarithms allows us to smooth the impact of outliers in the data.
```{r echo=FALSE}
coefficients(age_genderlog)
coefficients(age_gender)
```
**Conclusions**
Based on the two regression run in this homework, there is evidence to suggest that age, education and gender do have an impact on the level of wage that someone earns. While age and education both have a positive correlation with income earned, being female has a negative correlation with income earned. Whether we can make the leap to suggest each of these variables alone CAUSES high or low income is beyond the scope of this exercise. However, it would be remiss to ignore the confounding variables and externalities that would contribute to one's income, on top of gender, age and level of education.

Other variables I would like to pursue are linguistic ability. This could be particularly pertinent for highly educated immigrants who are not fluent in English or work predominantly in communities that are have low levels of English fluency. Including race or ancestry as a variable would be another important path to pursue. One variable that crossed my mind was family size - do people try to earn more to sustain larger families? Do they have larger families because they earn more? Or do we see the contrary?

Some restrictions that might be placed upon the data is to target degree fields in conjunction with relevant career fields. Many college graduates pursue roles in industry not directly related to their college major - discerning whether entering career fields that differ from studies has a positive, negative or neutral relationship on income is an interesting question (especially as a BA in History graduate!) Another change I would impose is to change the catergorization of wages to income total; this would capture more people pursuing multiple jobs - for example those whose chosen degrees allow them to work freelance and take second jobs.